{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95ee1e1-f750-4d08-9c7d-809e4644f6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai datasets plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "91e7db80-5ee0-43c3-8019-83302ca6a890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def process_text_before_evaluation(t: str):\n",
    "    \"\"\"Removes unnessecary symbols before evaluation\"\"\"\n",
    "\n",
    "    t = t.replace('\\n', ' ').strip()\n",
    "    t = t.replace('<eos>', '')\n",
    "    t = t.replace('<end_of_turn>', '')\n",
    "    t = re.sub(' +', ' ', t)\n",
    "    return t\n",
    "\n",
    "\n",
    "def prepare_sampled_text_for_evaluation(file_path: str, is_gemma=False):\n",
    "  \"\"\"Reads and preprocesses assistants reponses\"\"\"\n",
    "\n",
    "  with open(file_path) as f:\n",
    "    generated_annotations = json.load(f)\n",
    "\n",
    "  if is_gemma:\n",
    "    split_line = '<eos>model\\n'\n",
    "  else:\n",
    "    split_line = 'assistant<|end_header_id|>'\n",
    "\n",
    "  sampled_text_only = []\n",
    "\n",
    "  for index in generated_annotations['text']:\n",
    "    if split_line in generated_annotations['text'][index]:\n",
    "      assistant_reponse = generated_annotations['text'][index].split(split_line)[1]\n",
    "      sampled_text_only.append(process_text_before_evaluation(assistant_reponse))\n",
    "    else:\n",
    "      sampled_text_only.append('')\n",
    "\n",
    "  return sampled_text_only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313562de-9c0a-4a71-9212-e4cc31019750",
   "metadata": {},
   "source": [
    "#### Load human responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9755316-b0e5-4663-98a6-8508f216c294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab564345d0b44f62857bbb1876ba8839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c7d62d133c746dea665d24c2b129b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/1.41M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da6137f898044238757f1787e904e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/375k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d32a959b3d44c087f2438138060872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/2576 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9adea04be53d4ed887befc82ea7f8e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/687 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"prettyvampire/genius_poems_annotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "887098c5-6ecc-430b-8082-27f1bdba37bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_responses = list(map(lambda s: process_text_before_evaluation(s), dataset['test']['annotation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2e6e353-0dfe-45d5-ab03-bc5699d39e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total responses from human =  687\n"
     ]
    }
   ],
   "source": [
    "print('Total responses from human = ', len(human_responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "d900f3b1-50dd-46b1-a31b-127cc83bf32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‘Ancient Lord’ – nothing if not respectful. Escalus is the Duke’s right hand man. His name deliberately recalls the scales of justice – the play is obsessed with balancing right and wrong.'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_responses[80]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67aee263-31e7-4cde-b509-a2e8d29d4947",
   "metadata": {},
   "source": [
    "#### Load assistants responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90dcff93-fddb-4227-9f48-1336183162cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "files = [\n",
    "            'llama-3.1-8b-it-4bit',\n",
    "            'llama-3.1-8b-it-4bit-qlora',\n",
    "            'gemma-2-2b-it-lora'\n",
    "        ]\n",
    "assistants_responses = {}\n",
    "\n",
    "for fname in files:\n",
    "    assistant_reponses = prepare_sampled_text_for_evaluation(f\"./data/{fname}.json\", is_gemma='gemma' in fname)\n",
    "    assistants_responses[fname] = assistant_reponses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a5c5fe3e-7d4c-480d-b36c-b4b80c6be253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total responses from assistant llama-3.1-8b-it-4bit =  687\n",
      "The line \"ESCALUS, an ancient Lord\" from the \"Measure for Measure Characters of the Play\" by William Shakespeare refers to a character in the play named Escalus. In this context, \"ancient\" is an archaic term used to describe a person of high social status, wealth, and age. It is not necessarily referring to Escalus's physical age but rather his noble position in society. In the Elizabethan era, the term \"ancient\" was often used to describe a nobleman or a member of the aristocracy, conveying a sense of dignity, respect, and authority.\n",
      "\n",
      "Total responses from assistant llama-3.1-8b-it-4bit-qlora =  687\n",
      "Escalus is one of Claudio’s uncles and he appears only at the beginning of Act I Scene II as part of his role as Jailer-to-the-Gates where he reports on two different matters; Claudius’ situation with Juliet and Isabella being brought before him. He also reappears later in Act III when he serves as the messenger that delivers news about Angelo having taken advantage of Mariana (Claudio’s fiancée). Escalus has been shown throughout this scene to be very serious but somewhat naive because he takes what people tell him literally whereas others may not believe it or they have ul\n",
      "\n",
      "Total responses from assistant gemma-2-2b-it-lora =  687\n",
      "This is a bit of a trick question. Escalus is a character in the play, but he is not an ancient Lord.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for f in files:\n",
    "    print(f'Total responses from assistant {f} = ', len(assistants_responses[f]))\n",
    "    print(assistants_responses[f][80])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c257bc8-122f-4c2a-b4bd-9e0020db8000",
   "metadata": {},
   "source": [
    "#### Prepare batch file for OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7668f280-4566-4816-a3a5-8814aa6df406",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are given the correct annotation to a poem and 3 alternative annotations below.\n",
    "Vote for the alternative annotation that provides explanation most similar to the correct annotation.\n",
    "Provide the number of a most similar annotation as a response. Do not include any other details.\n",
    "\n",
    "<correct annotation>\n",
    "{human_response}\n",
    "</correct annotation>\n",
    "\n",
    "<alternative annotation 1>\n",
    "{reference_annotation_1}\n",
    "</alternative annotation 1>\n",
    "\n",
    "<alternative annotation 2>\n",
    "{reference_annotation_2}\n",
    "</alternative annotation 2>\n",
    "\n",
    "<alternative annotation 3>\n",
    "{reference_annotation_3}\n",
    "</alternative annotation 3>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "403255ab-4efc-4d9c-8b99-6c934008cb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_request(rid, prompt):\n",
    "    return {\n",
    "      \"custom_id\": f\"poems-annotation-request-{rid}\",\n",
    "      \"method\": \"POST\",\n",
    "      \"url\": \"/v1/chat/completions\",\n",
    "      \"body\": {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": [\n",
    "          {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an expert in poetry.\"\n",
    "          },\n",
    "          {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "          }\n",
    "        ],\n",
    "        \"max_tokens\": 64\n",
    "      }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2280fb52-bcb2-4d6a-8423-67759abe5622",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_requests = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9bde682e-10e3-457d-92f2-25107c273d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, annotations in enumerate(zip(human_responses, assistants_responses['llama-3.1-8b-it-4bit'], assistants_responses['llama-3.1-8b-it-4bit-qlora'], assistants_responses['gemma-2-2b-it-lora'])):\n",
    "    batch_requests.append(prepare_request(i, prompt=prompt.format(human_response=annotations[0],\n",
    "                                                               reference_annotation_1=annotations[1],\n",
    "                                                               reference_annotation_2=annotations[2],\n",
    "                                                               reference_annotation_3=annotations[3],\n",
    "                                                              )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f6eb51ea-de86-43e5-94af-57067c0929b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are given the correct annotation to a poem and 3 alternative annotations below.\n",
      "Vote for the alternative annotation that provides explanation most similar to the correct annotation.\n",
      "Provide the number of a most similar annotation as a response. Do not include any other details.\n",
      "\n",
      "<correct annotation>\n",
      "In the beginning of the poem the child absorbs the impressions of passive objects into his being; now the child is absorbing active traits and emotions. This ability to absorb one’s surroundings is one of the crowning feature’s of childhood. Children are perpetually engaged in the process of learning and making connections. The next lines go on to show the unforgettable and uncanny sensory details by which we recall familial relations. Mother has a certain smell. Father is rather exuberant. These are intimate details of family life that a child is sure to remember.\n",
      "</correct annotation>\n",
      "\n",
      "<alternative annotation 1>\n",
      "The lines \"They gave him afterward every day, they became part of him\" from Walt Whitman's poem \"There Was a Child Went Forth\" convey a profound idea about the relationship between a parent and their child. In this context, \"they\" refers to the child's parents, who are described as having given the child more of themselves than they were initially. The phrase \"They gave him afterward every day\" suggests that the parents continue to nurture and give their child a piece of themselves, their values, and their experiences, every day. This implies a constant and ongoing process of transmission of knowledge,\n",
      "</alternative annotation 1>\n",
      "\n",
      "<alternative annotation 2>\n",
      "This is one of the most important stanzas in the whole piece because it emphasizes how closely connected we are to our family members (and indeed everyone else). This line also hints towards how much time goes into making children; even after their conception, there’s still so many years until adulthood when you can be your “own” person again–if ever! It could also suggest that people should not forget or abandon those who raised them for better times ahead since they played such big roles throughout life too.” In addition,it highlights how loved ones become integrated within us over time due largely thanks parenting efforts made during\n",
      "</alternative annotation 2>\n",
      "\n",
      "<alternative annotation 3>\n",
      "The child is now a man, and the parents are now part of him.\n",
      "</alternative annotation 3>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(batch_requests[600]['body']['messages'][1]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "2d52b5cc-f1aa-4c55-8a0c-92e01d3468b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/batch_requests_3.jsonl', 'w') as f:\n",
    "    for entry in batch_requests:\n",
    "        json.dump(entry, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78cedcc-aebf-4e71-a530-20cde851e5d3",
   "metadata": {},
   "source": [
    "#### Creating batch request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6396dd41-e930-4e67-a987-59ecede21789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key='your key')\n",
    "\n",
    "batch_input_file = client.files.create(\n",
    "  file=open(\"./data/batch_requests_3.jsonl\", \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfb89cf-3c78-459d-99b1-44e23a72e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input_file_id = batch_input_file.id\n",
    "\n",
    "client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"poems annotation job\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a3c4e0-32c9-4460-8780-49e7c8f2334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.batches.retrieve(\"batch_67505f1e994c81919e79bb6c794ff6a3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6d06e09e-6ac7-454a-9c26-01947857e84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_response = client.files.content(\"file-GYidKYvWWn2Jz35mu9gt7x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "aa8240b1-aad9-46e2-bb85-63fbdb2f36d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/batch_responses_3.jsonl', 'w', encoding='utf-8') as f:\n",
    "    f.write(file_response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2f10f97f-c279-40e5-ba0e-7d71780a45b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "with open('./data/batch_responses_3.jsonl') as f:\n",
    "    for line in f:\n",
    "        responses.append(json.loads(line)['response']['body']['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4a7443c2-1c67-4bd8-9190-544a118a0208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879b0c40-0411-47a3-bcd5-7c53e7ed5856",
   "metadata": {},
   "source": [
    "**First barch responses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "71f3a179-bd3e-458c-9bd6-0961509a58bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'1': 457, '3': 154, '2': 76})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1639b29-f3dc-4810-a13f-d8d1c920d91e",
   "metadata": {},
   "source": [
    "**Second batch responses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e8bfb0cc-9996-4aad-b1f5-a1544e37dbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'1': 497,\n",
       "         '3': 108,\n",
       "         '2': 81,\n",
       "         \"I'm sorry, but I can't choose the most similar annotation without content in the reference annotations. Can you please provide the content for the three reference annotations?\": 1})"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b10d629-e5f9-4c74-907e-c779aeaf61c0",
   "metadata": {},
   "source": [
    "**Third batch responses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e63d60aa-9bae-4cf0-8719-52c4d7b4f535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'1': 365,\n",
       "         '3': 188,\n",
       "         '2': 110,\n",
       "         'Alternative annotation 1': 6,\n",
       "         'Alternative annotation 2': 5,\n",
       "         'Alternative annotation 3': 2,\n",
       "         'Annotation 3': 2,\n",
       "         'Annotation 1': 2,\n",
       "         'The number of the most similar annotation is 1.': 1,\n",
       "         'None of the alternative annotations provided are notably similar to the correct annotation, as they do not address the meter, rhythm, caesura, or the potential volta.': 1,\n",
       "         \"None of the alternative annotations seem to provide an explanation similar to the correct annotation. However, if I have to choose the closest one, alternative annotation 2 has some reference to psychological states and complexity, which could loosely relate to the craftsmanship and construction mentioned in the correct annotation, even if it doesn't directly address it. So\": 1,\n",
       "         'None of the alternative annotations provided closely aligns with the explanation given in the correct annotation.': 1,\n",
       "         'None of the alternative annotations are similar to the correct annotation given. Therefore, there is no number to provide.': 1,\n",
       "         'Annotation 2': 1,\n",
       "         'I am sorry, the alternative annotations seem to be missing, so I cannot determine which one is most similar to the correct annotation.': 1})"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004442a7-1325-4e41-8ee8-c44aca0e323b",
   "metadata": {},
   "source": [
    "### Charts & Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "6c3f9f8a-0758-4807-9138-4d6cd68ec9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "pyo.init_notebook_mode()\n",
    "plotly_template = pio.templates[\"plotly_white\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2ef7616b-8c60-41f9-85f3-b2f1cbf0e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"step\": 50, \"train\": 1.832800, \"validation\": 1.944836},\n",
    "    {\"step\": 100, \"train\": 1.897800, \"validation\": 1.826170},\n",
    "    {\"step\": 150, \"train\": 1.751900, \"validation\": 1.780192},\n",
    "    {\"step\": 200, \"train\": 1.8609000, \"validation\": 1.741657},\n",
    "    {\"step\": 250, \"train\": 2.079300, \"validation\": 1.714025},\n",
    "    {\"step\": 300, \"train\": 1.903500, \"validation\": 1.692754},\n",
    "    {\"step\": 350, \"train\": 1.720100, \"validation\": 1.681152},\n",
    "    {\"step\": 400, \"train\": 1.369700, \"validation\": 1.675502},\n",
    "    {\"step\": 450, \"train\": 1.974000, \"validation\": 1.671325},\n",
    "    {\"step\": 500, \"train\": 1.822900, \"validation\": 1.668295},\n",
    "    {\"step\": 550, \"train\": 1.076600, \"validation\": 1.666146},\n",
    "    {\"step\": 600, \"train\": 1.109300, \"validation\": 1.664798}\n",
    "]\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479d6662-91d3-4cc9-8743-745bf1ffa37f",
   "metadata": {},
   "source": [
    "### Training graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "95bf2c3d-70db-4c11-b3ba-fbba11b1960e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_184.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create traces\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['step'], y=df['validation'],\n",
    "                    mode='lines+markers',\n",
    "                    name='Validation Loss', line_color='orange'))\n",
    "fig.add_trace(go.Scatter(x=df['step'], y=df['train'],\n",
    "                    mode='lines+markers', name='Train Loss', line_color='black'))\n",
    "fig.update_layout(\n",
    "    plot_bgcolor='white',\n",
    "    title=\"One epoch training\"\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    mirror=True,\n",
    "    ticks='outside',\n",
    "    showline=True,\n",
    "    linecolor='black',\n",
    "    gridcolor='lightgrey',\n",
    "    title=\"Step number\"\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks='outside',\n",
    "    showline=True,\n",
    "    linecolor='black',\n",
    "    gridcolor='lightgrey',\n",
    "    title=\"Cross-Entropy Loss\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "1bc0dc19-43b2-44f2-81dd-134b02793aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    {\"model\": \"llama-3.1-8b-it-4bit\", \"metric\": \"ROUGE-1\", \"score\":0.256},\n",
    "    {\"model\": \"llama-3.1-8b-it-4bit\", \"metric\": \"BLEU\", \"score\": 0.171},\n",
    "    {\"model\": \"llama-3.1-8b-it-4bit\", \"metric\": \"BLEURT mean\", \"score\": -0.929},\n",
    "    {\"model\": \"llama-3.1-8b-it-4bit\", \"metric\": \"BERTScore F1 mean\", \"score\": 0.839},\n",
    "     \n",
    "    {\"model\": \"llama-3.1-8b-it-4bit-qlora\", \"metric\": \"ROUGE-1\", \"score\": 0.185},\n",
    "    {\"model\": \"llama-3.1-8b-it-4bit-qlora\", \"metric\": \"BLEU\", \"score\": 0.005},\n",
    "    {\"model\": \"llama-3.1-8b-it-4bit-qlora\", \"metric\": \"BLEURT mean\", \"score\": -0.926},\n",
    "    {\"model\": \"llama-3.1-8b-it-4bit-qlora\", \"metric\": \"BERTScore F1 mean\", \"score\": 0.836},\n",
    "\n",
    "    {\"model\": \"gemma-2-2b-it-lora\", \"metric\": \"ROUGE-1\", \"score\": 0.201},\n",
    "    {\"model\": \"gemma-2-2b-it-lora\", \"metric\": \"BLEU\", \"score\": 0.003},\n",
    "    {\"model\": \"gemma-2-2b-it-lora\", \"metric\": \"BLEURT mean\", \"score\": -1.134},\n",
    "    {\"model\": \"gemma-2-2b-it-lora\", \"metric\": \"BERTScore F1 mean\", \"score\": 0.852}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "13cc1c65-34b2-453f-b4c6-495942c38263",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9106f1c2-1cb0-40d0-95a8-6445fc11225e",
   "metadata": {},
   "source": [
    "### Rouge, Bleu, BleuRT, BERTScore Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "715a3cfc-7de4-44e5-9519-82111c5f307a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"420\"\n",
       "    src=\"iframe_figures/figure_219.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = metrics_df\n",
    "fig = px.histogram(df, x=\"metric\", y=\"score\",\n",
    "             color='model', barmode='group',\n",
    "             height=400, color_discrete_map={'llama-3.1-8b-it-4bit': 'orange', \n",
    "                                                   'llama-3.1-8b-it-4bit-qlora': 'grey', 'gemma-2-2b-it-lora': 'black'})\n",
    "fig.update_layout(\n",
    "    plot_bgcolor='white',\n",
    "    title=\"Standard Evaluation Metrics\"\n",
    ")\n",
    "fig.update_xaxes(\n",
    "    mirror=True,\n",
    "    ticks='outside',\n",
    "    showline=True,\n",
    "    linecolor='black',\n",
    "    gridcolor='lightgrey',\n",
    "    title=\"Metric\"\n",
    ")\n",
    "fig.update_yaxes(\n",
    "    mirror=True,\n",
    "    ticks='outside',\n",
    "    showline=True,\n",
    "    linecolor='black',\n",
    "    gridcolor='lightgrey',\n",
    "    title=\"Score\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4f1435-3173-4798-8aac-f36bc4c8f03c",
   "metadata": {},
   "source": [
    "### LLM as a Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "b1a71e3f-9273-428e-92c1-4a6f886895d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_228.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm_as_a_judge = [\n",
    "    {\"model\": \"llama-3.1-8b-it-4bit\", \"times_chosen\": 374},\n",
    "    {\"model\": \"llama-3.1-8b-it-4bit-qlora\",\"times_chosen\": 116},\n",
    "    {\"model\": \"gemma-2-2b-it-lora\", \"times_chosen\": 192},\n",
    "    {\"model\": \"none\", \"times_chosen\": 5},\n",
    "]\n",
    "\n",
    "fig = px.pie(pd.DataFrame(llm_as_a_judge), values='times_chosen', color='model',\n",
    "             names='model', title='GPT-4o Preference by Similarity to Human Response', color_discrete_map={'llama-3.1-8b-it-4bit': 'orange', \n",
    "                                                   'llama-3.1-8b-it-4bit-qlora': 'grey', 'gemma-2-2b-it-lora': 'black', 'none': 'lightgrey'})\n",
    "fig.update_traces(textinfo='percent+label')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
