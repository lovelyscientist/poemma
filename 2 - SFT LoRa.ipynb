{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597a4988",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://huggingface.co/google/gemma-7b/blob/main/examples/notebook_sft_peft.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14c54030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "os.environ[\"HF_TOKEN\"] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c541e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -q -U bitsandbytes==0.43.3\n",
    "!pip3 install -q -U peft==0.12.0\n",
    "!pip3 install -q -U trl==0.9.6\n",
    "!pip3 install -q -U accelerate==0.33.0\n",
    "!pip3 install -q -U datasets==2.21.0\n",
    "!pip3 install -q -U transformers==4.44.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "891ac246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c87d641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./data/annotations_dataset.csv').fillna('').sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b1d2874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    You are given the poem \"Well So That Is That\" by \"W. H. Auden\".\n",
      "    <poem>\n",
      "    Putting the decorations back into their cardboard boxes -\n",
      "Some have got broken - and carrying them up to the attic.\n",
      "The holly and the mistletoe must be taken down and burnt,\n",
      "And the children got ready for school. There are enough\n",
      "Leftovers to do, warmed up, for the rest of the week -\n",
      "Not that we have much appetite, having drunk such a lot,\n",
      "Stayed up so late, attempted - quite unsuccessfully -\n",
      "To love all of our relatives, and in general\n",
      "Grossly overestimated our powers. Once again\n",
      "As in previous years we have seen the actual Vision and failed\n",
      "To do more than entertain it as an agreeable\n",
      "Possibility, once again we have sent Him away,\n",
      "    Begging though to remain His disobedient servant,\n",
      "The promising child who cannot keep His word for long.\n",
      "    \n",
      "    </poem>\n",
      "    Explain the meaning of the following lines: \"Begging though to remain His disobedient servant,\n",
      "The promising child who cannot keep His word for long.\"\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def create_prompt(inputs: dict) -> str:\n",
    "    \"\"\"\n",
    "    Function that creates prompt for poetry explanation.\n",
    "    \"\"\"\n",
    "    return \"\"\"\n",
    "    You are given the poem \"{title}\" by \"{poet}\".\n",
    "    <poem>\n",
    "    {content_before}\n",
    "    {referent}\n",
    "    {context_after}\n",
    "    </poem>\n",
    "    Explain the meaning of the following lines: \"{referent}\"\n",
    "    \"\"\".format(\n",
    "        title=inputs['poem_title'],\n",
    "        poet=inputs['poet'],\n",
    "        content_before=inputs['content_before'],\n",
    "        context_after=inputs['context_after'],\n",
    "        referent=inputs['referent']\n",
    "    )\n",
    "\n",
    "print(create_prompt(inputs=dict(df.iloc[2770])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ade6450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content_before': \"The battle rent a cobweb diamond-strung\\nAnd cut a flower beside a ground bird's nest\\nBefore it stained a single human breast.\\nThe stricken flower bent double and so hung.\\nAnd still the bird revisited her young.\\nA butterfly its fall had dispossessed\\nA moment sought in air his flower of rest,\\nThen lightly stooped to it and fluttering clung.\\nOn the bare upland pasture there had spread\\nO'ernight 'twixt mullein stalks a wheel of thread\\nAnd straining cables wet with silver dew.\",\n",
       " 'referent': 'A sudden passing bullet shook it dry.',\n",
       " 'context_after': 'The indwelling spider ran to greet the fly,\\nBut finding nothing, sullenly withdrew.',\n",
       " 'annotation': 'The serenity is, as the reader no doubt anticipates, broken by the shot described in this snappy line. The dryness may represent the loss of a source of life that invigorates the natural — and human — worlds.',\n",
       " 'poet': 'Robert Frost',\n",
       " 'poem_title': 'Range-finding'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(df.iloc[2770])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c92d76",
   "metadata": {},
   "source": [
    "#### Split dataset into train/validation/test without intersections between poets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4191f388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_author(df, split_ratio=[0.7, 0.1]) -> list[pd.DataFrame]:\n",
    "    unique_poets_count = dict(df['poet'].value_counts())\n",
    "    \"\"\"Function that splits dataset into train/validation/test with no intersection between authors\"\"\"\n",
    "    \n",
    "    # set target counts for each subset\n",
    "    total_count = len(df)\n",
    "    count_deviation = total_count*0.01\n",
    "    train_count_target = int(total_count * split_ratio[0])\n",
    "    validation_count_target = int(total_count * split_ratio[1])\n",
    "    test_count_target = total_count - train_count_target - validation_count_target\n",
    "    train_poets, train_count = [], 0\n",
    "    validation_poets, validation_count = [], 0\n",
    "    \n",
    "    while abs(train_count-train_count_target) > count_deviation:\n",
    "        print('Selecting train dataset')\n",
    "        # define start values\n",
    "        train_poets, train_count = [], 0\n",
    "        unique_poets_list = df['poet'].value_counts().index.values.copy()\n",
    "\n",
    "        while train_count < train_count_target:\n",
    "            random_index = random.randint(0, len(unique_poets_list)-1)\n",
    "            train_poets.append(unique_poets_list[random_index])\n",
    "            train_count += unique_poets_count[unique_poets_list[random_index]]\n",
    "            unique_poets_list = np.delete(unique_poets_list, random_index)\n",
    "           \n",
    "    \n",
    "    while abs(validation_count-validation_count_target) > count_deviation:\n",
    "        print('Selecting validation dataset')\n",
    "        validation_poets, validation_count = [], 0\n",
    "        val_unique_poets_list = unique_poets_list.copy()\n",
    "        \n",
    "        while validation_count < validation_count_target:\n",
    "            random_index = random.randint(0, len(val_unique_poets_list)-1)\n",
    "            validation_poets.append(val_unique_poets_list[random_index])\n",
    "            validation_count += unique_poets_count[val_unique_poets_list[random_index]]\n",
    "            val_unique_poets_list = np.delete(val_unique_poets_list, random_index)\n",
    "    \n",
    "    # all left poets are for testing\n",
    "    test_poets = val_unique_poets_list\n",
    "    \n",
    "    print(train_count, len(df[df['poet'].isin(train_poets)]))\n",
    "    print(set(train_poets).intersection(validation_poets))\n",
    "    print(f\"Allowed deviation = {count_deviation}\")\n",
    "    print(f\"Train count (target={train_count_target}) = {len(df[df['poet'].isin(train_poets)])}\")\n",
    "    print(f\"Validation count (target={validation_count_target}) = {len(df[df['poet'].isin(validation_poets)])}\")\n",
    "    print(f\"Test count (target={test_count_target}) = {len(df[df['poet'].isin(test_poets)])}\")\n",
    "        \n",
    "    return df[df['poet'].isin(train_poets)], df[df['poet'].isin(validation_poets)], df[df['poet'].isin(test_poets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6efffcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting train dataset\n",
      "Selecting validation dataset\n",
      "Selecting validation dataset\n",
      "2576 2576\n",
      "set()\n",
      "Allowed deviation = 36.29\n",
      "Train count (target=2540) = 2576\n",
      "Validation count (target=362) = 366\n",
      "Test count (target=727) = 687\n"
     ]
    }
   ],
   "source": [
    "train_df, validation_df, test_df = split_by_author(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5b750d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('./data/annotations_dataset_train.csv', index=False)\n",
    "validation_df.to_csv('./data/annotations_dataset_validation.csv', index=False)\n",
    "test_df.to_csv('./data/annotations_dataset_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8922b9c",
   "metadata": {},
   "source": [
    "#### Create HF dataset from train/validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "df4d954b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\"train\": [\"./data/annotations_dataset_train.csv\"],\n",
    "             \"test\": [\"./data/annotations_dataset_validation.csv\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "cd2346a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50fbb6bf0d8a42b98954602fc66d43ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vtysch/.conda/envs/custom_llm/lib/python3.10/site-packages/datasets/download/streaming_download_manager.py:784: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4307641d5c64408b9f97d36323e830f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vtysch/.conda/envs/custom_llm/lib/python3.10/site-packages/datasets/download/streaming_download_manager.py:784: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n",
      "  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"csv\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2cd567da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2576, 366)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train']), len(dataset['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842e96dc",
   "metadata": {},
   "source": [
    "#### Load the model from HF hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3dc109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, GemmaTokenizer\n",
    "\n",
    "model_id = \"google/gemma-2-2b-it\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=os.environ['HF_TOKEN'])\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                             #quantization_config=bnb_config,\n",
    "                                             device_map={\"mps\":0},\n",
    "                                             token=os.environ['HF_TOKEN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4cf8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = create_prompt(inputs=dict(df.iloc[2770]))\n",
    "device = \"cuda:0\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens=100)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d793d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    target_modules=[\"q_proj\", \"o_proj\", \"k_proj\", \"v_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e5afe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data = load_dataset(\"Abirate/english_quotes\")\n",
    "#data = data.map(lambda samples: tokenizer(samples[\"quote\"]), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d3f4067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'quote': '“Be yourself; everyone else is already taken.”',\n",
       " 'author': 'Oscar Wilde',\n",
       " 'tags': ['be-yourself',\n",
       "  'gilbert-perreira',\n",
       "  'honesty',\n",
       "  'inspirational',\n",
       "  'misattributed-oscar-wilde',\n",
       "  'quote-investigator']}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a034d7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e556e66aa264562b8907d2970e0a372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afd9ba912b24617ab795c11afa08a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(lambda samples: tokenizer(samples['referent']), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dacc1109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content_before': 'About suffering they were never wrong,\\nThe Old Masters; how well they understood\\nIts human position; how it takes place\\nWhile someone else is eating or opening a window or just walking dully along;\\nHow, when the aged are reverently, passionately waiting\\nFor the miraculous birth, there always must be\\nChildren who did not specially want it to happen, skating\\nOn a pond at the edge of the wood:\\nThey never forgot\\nThat even the dreadful martyrdom must run its course',\n",
       " 'referent': \"Anyhow in a corner, some untidy spot\\nWhere the dogs go on with their doggy life and the torturer's horse\\nScratches its innocent behind on a tree.\",\n",
       " 'context_after': \"In Breughel's Icarus, for instance: how everything turns away\\nQuite leisurely from the disaster; the ploughman may\\nHave heard the splash, the forsaken cry,\",\n",
       " 'annotation': 'After the dramatic climax of the ‘dreadful martyrdom’, the tone changes to conversational, with the words ‘Anyhow’, ‘doggy’ and ‘behind’, a characteristic of the poem. \\n The ‘innocent behind’ may be a reference to another of Breughel’s paintings, ‘The Slaughter of the Innocents.’  The animals are oblivious to the brutality of those in power, a reflection of human capacity to become inured to suffering of others. \\n',\n",
       " 'poet': 'W. H. Auden',\n",
       " 'poem_title': 'Musée des Beaux Arts',\n",
       " 'input_ids': [2,\n",
       "  233448,\n",
       "  575,\n",
       "  476,\n",
       "  10429,\n",
       "  235269,\n",
       "  1009,\n",
       "  748,\n",
       "  122537,\n",
       "  7039,\n",
       "  108,\n",
       "  6006,\n",
       "  573,\n",
       "  12075,\n",
       "  871,\n",
       "  611,\n",
       "  675,\n",
       "  1024,\n",
       "  208447,\n",
       "  1913,\n",
       "  578,\n",
       "  573,\n",
       "  19882,\n",
       "  6995,\n",
       "  235303,\n",
       "  235256,\n",
       "  10468,\n",
       "  108,\n",
       "  4411,\n",
       "  2653,\n",
       "  2127,\n",
       "  1277,\n",
       "  30540,\n",
       "  5470,\n",
       "  611,\n",
       "  476,\n",
       "  5421,\n",
       "  235265],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d4e1d301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1\\n2'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'\\n'.join([\"1\", \"2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e7b8e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "custom_llm",
   "language": "python",
   "name": "custom_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
